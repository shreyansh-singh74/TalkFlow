# TalkFlow Backend - Speech-to-Text Only

A simple FastAPI backend that converts audio to text using Whisper.

## What It Does

**Simple Flow:**
```
Frontend sends audio â†’ Backend transcribes â†’ Returns text
```

## Project Structure

```
backend/
â”œâ”€â”€ main.py                          # Application entry point
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ app/
    â”œâ”€â”€ api/routes/
    â”‚   â”œâ”€â”€ health.py               # Health check endpoints
    â”‚   â””â”€â”€ transcription.py        # Audio transcription endpoint
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ config.py               # Configuration
    â”‚   â””â”€â”€ models.py               # Whisper model loading
    â”œâ”€â”€ services/
    â”‚   â””â”€â”€ transcription_service.py # Transcription logic
    â””â”€â”€ utils/
        â””â”€â”€ audio_utils.py          # Audio conversion
```

## Installation

1. Create and activate virtual environment:
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Ensure ffmpeg is installed:
```bash
# Ubuntu/Debian
sudo apt-get install ffmpeg

# macOS
brew install ffmpeg
```

## Running the Server

```bash
# Development
python3 main.py

# Or with auto-reload
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Server will start at: `http://localhost:8000`

## API Endpoints

### Health Check
```
GET /
GET /health
```

Response:
```json
{
  "status": "healthy",
  "whisper_model": "tiny"
}
```

### Transcribe Audio
```
POST /transcribe
Content-Type: multipart/form-data

Body: { audio: <audio file> }
```

Response:
```json
{
  "transcript": "transcribed text here",
  "success": true
}
```

## Example Usage

### Using curl
```bash
curl -X POST http://localhost:8000/transcribe \
  -F "audio=@recording.webm"
```

### Using JavaScript (Frontend)
```javascript
const formData = new FormData();
formData.append('audio', audioBlob, 'recording.webm');

const response = await fetch('http://localhost:8000/transcribe', {
  method: 'POST',
  body: formData
});

const data = await response.json();
console.log(data.transcript); // "Hello, this is the transcribed text"
```

## Configuration

Edit `app/core/config.py` to modify:
- **WHISPER_MODEL**: Model size (tiny/base/small/medium/large)
- **ALLOWED_ORIGINS**: CORS origins for frontend
- **AUDIO_SAMPLE_RATE**: Audio sample rate (default: 16000)

## Features

âœ… Speech-to-text using faster-whisper  
âœ… Automatic audio format conversion  
âœ… CORS support for frontend integration  
âœ… Clean, simple codebase  
âœ… Fast and efficient  

## What Was Removed

This is a simplified version. Removed features:
- âŒ AI conversation (Gemini)
- âŒ Text-to-speech (TTS)
- âŒ Conversation memory
- âŒ Audio file serving

**This backend ONLY does transcription!**

## Dependencies

- **fastapi**: Web framework
- **uvicorn**: ASGI server
- **faster-whisper**: Efficient Whisper implementation
- **python-multipart**: File upload support
- **python-dotenv**: Environment variables

## Environment Variables (Optional)

Create a `.env` file:
```env
WHISPER_MODEL=tiny
```

Available models: `tiny`, `base`, `small`, `medium`, `large-v3`

## Troubleshooting

**Port already in use:**
```bash
lsof -ti:8000 | xargs kill -9
```

**FFmpeg not found:**
```bash
# Install ffmpeg
sudo apt-get install ffmpeg  # Ubuntu
brew install ffmpeg          # macOS
```

## Production Deployment

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

---

**Simple. Fast. Just transcription.** ğŸ¤â†’ğŸ“
