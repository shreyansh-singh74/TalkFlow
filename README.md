# TalkFlow

> **AI-Powered Language Learning Platform** - Practice pronunciation with personalized AI tutors and track your progress through interactive meetings.

## ğŸŒŸ Overview

TalkFlow is a comprehensive language learning platform that combines AI-powered pronunciation feedback with an intuitive dashboard for managing learning sessions. Create custom AI tutors, schedule practice meetings, and get real-time feedback on your pronunciation using advanced speech recognition and AI technology.

## âœ¨ Key Features

- ğŸ¤– **Custom AI Tutors** - Create personalized language learning agents with custom instructions
- ğŸ¤ **Real-time Pronunciation Feedback** - Get instant feedback using OpenAI Whisper and Google Gemini
- ğŸ“… **Meeting Management** - Schedule, track, and manage your learning sessions
- ğŸ“Š **Progress Tracking** - Monitor your improvement with detailed session analytics
- ğŸ” **User Authentication** - Secure login and user management system
- ğŸ“± **Responsive Design** - Works seamlessly on desktop and mobile devices

## ğŸ› ï¸ Tech Stack

### Frontend
- **Next.js 15** with React 19
- **TypeScript** for type safety
- **Tailwind CSS** for styling
- **Radix UI** components
- **Better Auth** for authentication
- **Drizzle ORM** for database management

### Backend
- **FastAPI** for API development
- **OpenAI Whisper** for speech-to-text transcription
- **Google Gemini** for AI-powered feedback
- **Python 3.12** with async support

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+ and npm
- Python 3.12+
- ffmpeg (for audio processing)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/TalkFlow.git
   cd TalkFlow
   ```

2. **Run the setup script**
   ```bash
   chmod +x setup.sh
   ./setup.sh
   ```

3. **Configure environment variables**
   ```bash
   # Create .env file in the root directory
   GEMINI_API_KEY="your-gemini-api-key-here"
   WHISPER_MODEL="tiny"  # Options: tiny, base, small, medium, large
   ```

4. **Start the application**
   
   **Backend:**
   ```bash
   cd backend
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   python main.py
   ```
   
   **Frontend:**
   ```bash
   cd web
   npm run dev
   ```

5. **Access the application**
   - Main app: http://localhost:3000
   - Test recorder: http://localhost:3000/test-recorder

## ğŸ“– How It Works

1. **Create an Account** - Sign up and create your profile
2. **Build AI Tutors** - Create custom language learning agents with specific instructions
3. **Schedule Meetings** - Plan practice sessions with your AI tutors
4. **Practice Pronunciation** - Record audio and receive real-time feedback
5. **Track Progress** - Monitor your improvement over time

## ğŸ¯ Getting Started Guide

### Creating Your First AI Tutor
1. Navigate to the Agents section
2. Click "Create New Agent"
3. Provide a name and detailed instructions for your tutor
4. Save and start scheduling meetings

### Practicing Pronunciation
1. Go to your scheduled meeting
2. Click the microphone button to start recording
3. Speak clearly into your device
4. Stop recording to receive AI feedback
5. Review pronunciation tips and practice suggestions

## ğŸ”§ Configuration

### Whisper Models
Choose the right model for your needs:
- `tiny` - Fastest, good for testing
- `base` - Balanced speed and accuracy
- `small` - Better accuracy, slower
- `medium` - High accuracy, best for production
- `large` - Highest accuracy, requires more resources

### API Keys
- **Gemini API**: Get your free API key from [Google AI Studio](https://ai.google.dev/)
- **Rate Limits**: Free tier includes 15 requests per minute

## ğŸ› Troubleshooting

### Common Issues

**Audio not recording:**
- Ensure microphone permissions are granted
- Check browser compatibility (Chrome/Firefox recommended)
- Verify HTTPS in production environments

**Transcription errors:**
- Speak clearly and at moderate pace
- Reduce background noise
- Try different Whisper models

**API errors:**
- Verify your Gemini API key is correct
- Check rate limits (15 requests/minute for free tier)
- Ensure stable internet connection

## ğŸ“ Project Structure

```
TalkFlow/
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ main.py             # Main server file
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ venv/              # Virtual environment
â”œâ”€â”€ web/                    # Next.js frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/           # App router pages
â”‚   â”‚   â”œâ”€â”€ components/    # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ modules/       # Feature modules
â”‚   â”‚   â”œâ”€â”€ lib/          # Utilities and configurations
â”‚   â”‚   â””â”€â”€ db/           # Database schema
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ setup.sh               # Automated setup script
â””â”€â”€ README.md
```

## ğŸš€ Deployment

### Production Setup
1. Set up environment variables for production
2. Configure HTTPS for microphone access
3. Use a production-grade database
4. Implement proper error handling and logging
5. Set up monitoring and analytics

### Docker Support
```bash
# Build and run with Docker Compose
docker-compose up --build
```

## ğŸ“Š Performance

- **Transcription Speed**: ~2-5 seconds for 10-second audio
- **API Response Time**: <500ms for feedback generation
- **Supported Audio Formats**: WebM, MP3, WAV
- **Browser Support**: Chrome, Firefox, Safari, Edge

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [OpenAI Whisper](https://github.com/openai/whisper) for speech recognition
- [Google Gemini](https://ai.google.dev/) for AI-powered feedback
- [FastAPI](https://fastapi.tiangolo.com/) for the backend framework
- [Next.js](https://nextjs.org/) for the frontend framework

## ğŸ“ Support

- ğŸ“§ Email: support@lingualive.com
- ğŸ’¬ Discord: [Join our community](https://discord.gg/lingualive)
- ğŸ“– Documentation: [docs.lingualive.com](https://docs.lingualive.com)

---

**Start your language learning journey today! ğŸ“**